Using backend: pytorch
main start at this time 1648527863.4244747
-----------------------------------------before load data 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
success----------------------------------------
60
500
19157
# Nodes: 19717
# Edges: 88648
# Train: 60
# Val: 500
# Test: 19157
# Classes: 3

in feats:  500
----------------------------------------before generate_dataloader_block 
 Nvidia-smi: 1.0369873046875 GB
    Memory Allocated: 0.0075511932373046875  GigaBytes
Max Memory Allocated: 0.0075511932373046875  GigaBytes

The real block id is  2
get_global_graph_edges_ids_block function  spend 0.0016529560089111328
random selection method range initialization spend 0.00018405914306640625
time for parepare:  4.1484832763671875e-05
local_output_nid generation:  3.266334533691406e-05
local_in_edges_tensor generation:  0.00020647048950195312
mini_batch_src_global generation:  3.170967102050781e-05
r_  generation:  0.0011954307556152344
----------------------check_connections_block total spend ----------------------------- 0.001615762710571289
generate_one_block  0.0013418197631835938
The real block id is  1
get_global_graph_edges_ids_block function  spend 0.0010361671447753906
gen group dst list time:  3.528594970703125e-05
time for parepare:  0.00022530555725097656
local_output_nid generation:  3.0517578125e-05
local_in_edges_tensor generation:  0.0002384185791015625
mini_batch_src_global generation:  0.00011324882507324219
r_  generation:  0.0011355876922607422
----------------------check_connections_block total spend ----------------------------- 0.0020787715911865234
generate_one_block  0.0026874542236328125
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.000995635986328125
gen group dst list time:  4.9114227294921875e-05
time for parepare:  0.0006725788116455078
local_output_nid generation:  0.00015616416931152344
local_in_edges_tensor generation:  0.0005266666412353516
mini_batch_src_global generation:  0.0005419254302978516
r_  generation:  0.005765676498413086
----------------------check_connections_block total spend ----------------------------- 0.00950765609741211
generate_one_block  0.00902104377746582
-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.0369873046875 GB
    Memory Allocated: 0.0075511932373046875  GigaBytes
Max Memory Allocated: 0.0075511932373046875  GigaBytes

connection checking time:  0.011586427688598633
block generation total time  0.011708498001098633
average batch blocks generation time:  0.011708498001098633
----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.1170654296875 GB
    Memory Allocated: 0.021858692169189453  GigaBytes
Max Memory Allocated: 0.021858692169189453  GigaBytes

torch.Size([7581, 500])
torch.Size([2532, 16])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.8846435546875 GB
    Memory Allocated: 0.6262903213500977  GigaBytes
Max Memory Allocated: 0.6698141098022461  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.00527191162109375 |0.36527037620544434 |0.6264359951019287 |0.0003190040588378906 |0.1630256175994873 |0.011759519577026367 |
----------------------------------------------------------pseudo_mini_loss sum 1.9406918287277222
 Run 0| Epoch 0 |
Number of nodes for computation during this epoch:  10467
Number of first layer input nodes during this epoch:  7581
----------------------------------------before generate_dataloader_block 
 Nvidia-smi: 1.8846435546875 GB
    Memory Allocated: 0.04474496841430664  GigaBytes
Max Memory Allocated: 0.6698141098022461  GigaBytes

The real block id is  2
get_global_graph_edges_ids_block function  spend 0.0006110668182373047
random selection method range initialization spend 0.00013756752014160156
time for parepare:  5.8650970458984375e-05
local_output_nid generation:  2.4080276489257812e-05
local_in_edges_tensor generation:  0.00022339820861816406
mini_batch_src_global generation:  3.933906555175781e-05
r_  generation:  0.0001437664031982422
----------------------check_connections_block total spend ----------------------------- 0.0006189346313476562
generate_one_block  0.0016241073608398438
The real block id is  1
get_global_graph_edges_ids_block function  spend 0.0006706714630126953
gen group dst list time:  2.5033950805664062e-05
time for parepare:  0.00031566619873046875
local_output_nid generation:  4.172325134277344e-05
local_in_edges_tensor generation:  0.00028896331787109375
mini_batch_src_global generation:  0.0001609325408935547
r_  generation:  0.0013904571533203125
----------------------check_connections_block total spend ----------------------------- 0.0025610923767089844
generate_one_block  0.0027379989624023438
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.0009846687316894531
gen group dst list time:  5.53131103515625e-05
time for parepare:  0.0006291866302490234
local_output_nid generation:  0.00017261505126953125
local_in_edges_tensor generation:  0.0005326271057128906
mini_batch_src_global generation:  0.0006000995635986328
r_  generation:  0.005892276763916016
----------------------check_connections_block total spend ----------------------------- 0.009753704071044922
generate_one_block  0.009828567504882812
-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.8846435546875 GB
    Memory Allocated: 0.04474496841430664  GigaBytes
Max Memory Allocated: 0.6698141098022461  GigaBytes

connection checking time:  0.012314796447753906
block generation total time  0.012566566467285156
average batch blocks generation time:  0.012566566467285156
block dataloader generation time/epoch 0.042731523513793945
----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.8846435546875 GB
    Memory Allocated: 0.04454469680786133  GigaBytes
Max Memory Allocated: 0.6698141098022461  GigaBytes

torch.Size([7602, 500])
torch.Size([2537, 16])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.8983154296875 GB
    Memory Allocated: 0.6586942672729492  GigaBytes
Max Memory Allocated: 0.7028889656066895  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.0048465728759765625 |0.0005288124084472656 |0.13421273231506348 |0.0001354217529296875 |0.16720223426818848 |0.006773471832275391 |
----------------------------------------------------------pseudo_mini_loss sum 1.449492335319519
Total (block generation + training)time/epoch 0.3589818477630615
Training time/epoch 0.31607961654663086
Training time without block to device /epoch 0.3155508041381836
Training time without total dataloading part /epoch 0.30832386016845703
load block tensor time/epoch 0.0048465728759765625
block to device time/epoch 0.0005288124084472656
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
 Run 0| Epoch 1 |
Number of nodes for computation during this epoch:  10493
Number of first layer input nodes during this epoch:  7602
