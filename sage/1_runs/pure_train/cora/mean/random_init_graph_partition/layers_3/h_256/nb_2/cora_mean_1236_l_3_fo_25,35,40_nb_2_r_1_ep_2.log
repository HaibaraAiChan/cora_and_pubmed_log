main start at this time 1648602078.6411047
-----------------------------------------before load data 
 Nvidia-smi: 11.1502685546875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
success----------------------------------------
140
500
2068
# Nodes: 2708
# Edges: 10556
# Train: 140
# Val: 500
# Test: 2068
# Classes: 7

in feats:  1433
----------------------------------------before generate_dataloader_block 
 Nvidia-smi: 12.0155029296875 GB
    Memory Allocated: 0.0032434463500976562  GigaBytes
Max Memory Allocated: 0.0032434463500976562  GigaBytes

{'VmPeak': 20804.74609375, 'VmSize': 20804.74609375, 'VmHWM': 3615.34765625, 'VmRSS': 3615.34765625}
The real block id is  2
get_global_graph_edges_ids_block function  spend 0.0006377696990966797
global_2_local 7.772445678710938e-05
---------------------------- variant graph partition start---------------------
random_init for graph_partition spend:  9.179115295410156e-05
before graph partition 
		315, 381, 

{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-

-------------------------------------------------------------  compare batch pair  (0,1)
				 list len:
				70, 70, 


	preparing two sides time :  0.00028634071350097656
	Initialize BitList time :  2.0742416381835938e-05
	getRedundancyCost: time   2.6226043701171875e-06

					length of partitions 315, 381

	before terminate 1 the average redundancy rate is:  1.0807453416149069
	--------------------------------------------------------------------------------
	 walk terminate 1 start-------
						 current side  1
Using backend: pytorch
			 the number of node to move is : 0
			 --group redundancy rate update  step :0  side 1
			 redundancy rate (ration_mean, ratio_A, ratio_B): 1.0807453416149069,  0.9782608695652174,  1.1832298136645962
						 current side  0
			 the number of node to move is : 0
			 --group redundancy rate update  step :1  side 0
			 redundancy rate (ration_mean, ratio_A, ratio_B): 1.0807453416149069,  0.9782608695652174,  1.1832298136645962
						 current side  1
			 the number of node to move is : 0
			 --group redundancy rate update  step :2  side 1
			 redundancy rate (ration_mean, ratio_A, ratio_B): 1.0807453416149069,  0.9782608695652174,  1.1832298136645962
	walk terminate 1 spend time 4.30268120765686
				 improvement:  False
0
side is 1
	 walk step 0  partition 
		315, 381, 


	--------------------------------------------------end of batch 0
after graph partition
graph partition algorithm spend time 4.306363105773926
partition_len_list
[315, 381]
random_init_graph_partition selection method range initialization spend 4.306770324707031
time for parepare:  0.00017380714416503906
local_output_nid generation:  1.52587890625e-05
local_in_edges_tensor generation:  0.001425027847290039
mini_batch_src_global generation:  0.00014209747314453125
r_  generation:  0.013512611389160156
local_output_nid generation:  0.00017571449279785156
local_in_edges_tensor generation:  0.00021076202392578125
mini_batch_src_global generation:  9.775161743164062e-05
r_  generation:  0.0002853870391845703
----------------------check_connections_block total spend ----------------------------- 0.016627073287963867
generate_one_block  0.01407003402709961
generate_one_block  0.0013628005981445312
The real block id is  1
get_global_graph_edges_ids_block function  spend 0.002112865447998047
gen group dst list time:  3.266334533691406e-05
time for parepare:  0.0006127357482910156
local_output_nid generation:  3.886222839355469e-05
local_in_edges_tensor generation:  0.0004520416259765625
mini_batch_src_global generation:  0.0002429485321044922
r_  generation:  0.0007801055908203125
local_output_nid generation:  3.170967102050781e-05
local_in_edges_tensor generation:  0.00040531158447265625
mini_batch_src_global generation:  0.00017595291137695312
r_  generation:  0.000797271728515625
----------------------check_connections_block total spend ----------------------------- 0.004263162612915039
generate_one_block  0.0018665790557861328
generate_one_block  0.0020415782928466797
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.001623392105102539
gen group dst list time:  5.698204040527344e-05
time for parepare:  0.00022792816162109375
local_output_nid generation:  7.05718994140625e-05
local_in_edges_tensor generation:  0.0012562274932861328
mini_batch_src_global generation:  0.0003933906555175781
r_  generation:  0.0018382072448730469
local_output_nid generation:  8.678436279296875e-05
local_in_edges_tensor generation:  0.0008037090301513672
mini_batch_src_global generation:  0.0005395412445068359
r_  generation:  0.0020399093627929688
----------------------check_connections_block total spend ----------------------------- 0.008520364761352539
generate_one_block  0.0029795169830322266
generate_one_block  0.003725290298461914
-----------------------------------------after block dataloader generation 
 Nvidia-smi: 12.0155029296875 GB
    Memory Allocated: 0.0032434463500976562  GigaBytes
Max Memory Allocated: 0.0032434463500976562  GigaBytes

{'VmPeak': 20808.8125, 'VmSize': 20656.64453125, 'VmHWM': 3620.1328125, 'VmRSS': 3620.1328125}
connection checking time:  0.012783527374267578
block generation total time  0.010612964630126953
average batch blocks generation time:  0.0053064823150634766
----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 12.0799560546875 GB
    Memory Allocated: 0.012763023376464844  GigaBytes
Max Memory Allocated: 0.012763023376464844  GigaBytes

{'VmPeak': 21011.5390625, 'VmSize': 20979.54296875, 'VmHWM': 3910.7421875, 'VmRSS': 3910.7421875}
torch.Size([1773, 1433])
torch.Size([997, 256])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 12.2440185546875 GB
    Memory Allocated: 0.01720285415649414  GigaBytes
Max Memory Allocated: 0.01749563217163086  GigaBytes

{'VmPeak': 21753.1875, 'VmSize': 21749.29296875, 'VmHWM': 4604.3359375, 'VmRSS': 4604.3359375}
----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 12.2615966796875 GB
    Memory Allocated: 0.01697683334350586  GigaBytes
Max Memory Allocated: 0.026378154754638672  GigaBytes

{'VmPeak': 21760.0078125, 'VmSize': 21760.0078125, 'VmHWM': 4615.7109375, 'VmRSS': 4615.7109375}
torch.Size([1953, 1433])
torch.Size([1181, 256])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 12.2635498046875 GB
    Memory Allocated: 0.022432327270507812  GigaBytes
Max Memory Allocated: 0.026378154754638672  GigaBytes

{'VmPeak': 21760.0078125, 'VmSize': 21760.0078125, 'VmHWM': 4615.7109375, 'VmRSS': 4615.7109375}
{'VmPeak': 21760.0078125, 'VmSize': 21760.0078125, 'VmHWM': 4616.56640625, 'VmRSS': 4616.56640625}
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.00860130786895752 |0.18496286869049072 |0.4024420976638794 |0.00023245811462402344 |0.0054934024810791016 |0.0020737648010253906 |
----------------------------------------------------------pseudo_mini_loss sum 4.315392017364502
{'VmPeak': 21760.0078125, 'VmSize': 21760.0078125, 'VmHWM': 4616.56640625, 'VmRSS': 4616.56640625}
 Run 0| Epoch 0 |
Number of nodes for computation during this epoch:  6600
Number of first layer input nodes during this epoch:  3726
----------------------------------------before generate_dataloader_block 
 Nvidia-smi: 12.2635498046875 GB
    Memory Allocated: 0.024103641510009766  GigaBytes
Max Memory Allocated: 0.029570579528808594  GigaBytes

{'VmPeak': 21760.0078125, 'VmSize': 21760.0078125, 'VmHWM': 4616.56640625, 'VmRSS': 4616.56640625}
The real block id is  2
get_global_graph_edges_ids_block function  spend 0.0005156993865966797
global_2_local 7.700920104980469e-05
---------------------------- variant graph partition start---------------------
random_init for graph_partition spend:  6.67572021484375e-05
before graph partition 
		352, 341, 

{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-

-------------------------------------------------------------  compare batch pair  (0,1)
				 list len:
				70, 70, 


	preparing two sides time :  0.00027251243591308594
	Initialize BitList time :  1.8596649169921875e-05
	getRedundancyCost: time   2.6226043701171875e-06

					length of partitions 352, 341

	before terminate 1 the average redundancy rate is:  1.0760869565217392
	--------------------------------------------------------------------------------
	 walk terminate 1 start-------
						 current side  0
			 the number of node to move is : 0
			 --group redundancy rate update  step :0  side 0
			 redundancy rate (ration_mean, ratio_A, ratio_B): 1.0760869565217392,  1.093167701863354,  1.0590062111801242
						 current side  1
			 redundancy will reduce  0.0015527950310558758
			 the number of node to move is : 2
			 --group redundancy rate update  step :1  side 1
			 redundancy rate (ration_mean, ratio_A, ratio_B): 1.0745341614906834,  1.1211180124223603,  1.0279503105590062
						 current side  0
			 redundancy will reduce  0.0015527950310558758
			 the number of node to move is : 2
			 --group redundancy rate update  step :2  side 0
			 redundancy rate (ration_mean, ratio_A, ratio_B): 1.0745341614906834,  1.0776397515527951,  1.0714285714285714
	walk terminate 1 spend time 5.336668014526367
				 improvement:  True
	 walk terminate 1 start-------
						 current side  0
			 redundancy will reduce  0.0031055900621117516
			 the number of node to move is : 2
			 --group redundancy rate update  step :0  side 0
			 redundancy rate (ration_mean, ratio_A, ratio_B): 1.0729813664596275,  1.049689440993789,  1.0962732919254659
						 current side  1
			 redundancy will reduce  0.0031055900621117516
			 the number of node to move is : 2
			 --group redundancy rate update  step :1  side 1
			 redundancy rate (ration_mean, ratio_A, ratio_B): 1.0729813664596275,  1.093167701863354,  1.0527950310559007
						 current side  0
			 redundancy will reduce  0.007763975155279601
			 the number of node to move is : 2
			 --group redundancy rate update  step :2  side 0
			 redundancy rate (ration_mean, ratio_A, ratio_B): 1.0683229813664596,  1.0590062111801242,  1.0776397515527951
	walk terminate 1 spend time 5.236400842666626
				 improvement:  True
1
side is 1
	 walk step 1  partition 
		341, 347, 


	--------------------------------------------------end of batch 0
after graph partition
graph partition algorithm spend time 10.576658010482788
partition_len_list
[341, 347]
random_init_graph_partition selection method range initialization spend 10.577215671539307
time for parepare:  0.00016307830810546875
local_output_nid generation:  2.09808349609375e-05
local_in_edges_tensor generation:  0.033592939376831055
mini_batch_src_global generation:  0.0001380443572998047
r_  generation:  0.0005083084106445312
local_output_nid generation:  1.1444091796875e-05
local_in_edges_tensor generation:  0.0002033710479736328
mini_batch_src_global generation:  7.104873657226562e-05
r_  generation:  0.00024771690368652344
----------------------check_connections_block total spend ----------------------------- 0.035892486572265625
generate_one_block  0.02611064910888672
generate_one_block  0.0013785362243652344
The real block id is  1
get_global_graph_edges_ids_block function  spend 0.0019283294677734375
gen group dst list time:  3.528594970703125e-05
time for parepare:  0.0006158351898193359
local_output_nid generation:  4.0531158447265625e-05
local_in_edges_tensor generation:  0.0005564689636230469
mini_batch_src_global generation:  0.0002980232238769531
r_  generation:  0.0007181167602539062
local_output_nid generation:  2.86102294921875e-05
local_in_edges_tensor generation:  0.00031685829162597656
mini_batch_src_global generation:  0.00020384788513183594
r_  generation:  0.0007150173187255859
----------------------check_connections_block total spend ----------------------------- 0.004397153854370117
generate_one_block  0.0019545555114746094
generate_one_block  0.0018701553344726562
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.001405477523803711
gen group dst list time:  5.817413330078125e-05
time for parepare:  0.00022649765014648438
local_output_nid generation:  7.367134094238281e-05
local_in_edges_tensor generation:  0.001119852066040039
mini_batch_src_global generation:  0.0005648136138916016
r_  generation:  0.0018291473388671875
local_output_nid generation:  8.249282836914062e-05
local_in_edges_tensor generation:  0.00039124488830566406
mini_batch_src_global generation:  0.0005631446838378906
r_  generation:  0.0018019676208496094
----------------------check_connections_block total spend ----------------------------- 0.00834035873413086
generate_one_block  0.005846977233886719
generate_one_block  0.011509418487548828
-----------------------------------------after block dataloader generation 
 Nvidia-smi: 12.2635498046875 GB
    Memory Allocated: 0.024103641510009766  GigaBytes
Max Memory Allocated: 0.029570579528808594  GigaBytes

{'VmPeak': 21824.0390625, 'VmSize': 21824.0234375, 'VmHWM': 4618.1875, 'VmRSS': 4618.1875}
connection checking time:  0.012737512588500977
block generation total time  0.021181106567382812
average batch blocks generation time:  0.010590553283691406
block dataloader generation time/epoch 10.687721252441406
----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 12.2830810546875 GB
    Memory Allocated: 0.02319812774658203  GigaBytes
Max Memory Allocated: 0.03356790542602539  GigaBytes

{'VmPeak': 21897.9296875, 'VmSize': 21865.93359375, 'VmHWM': 4627.5390625, 'VmRSS': 4627.5390625}
torch.Size([1813, 1433])
torch.Size([1044, 256])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 12.2830810546875 GB
    Memory Allocated: 0.028287410736083984  GigaBytes
Max Memory Allocated: 0.03356790542602539  GigaBytes

{'VmPeak': 21897.9296875, 'VmSize': 21865.93359375, 'VmHWM': 4627.5390625, 'VmRSS': 4627.5390625}
----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 12.2830810546875 GB
    Memory Allocated: 0.02354145050048828  GigaBytes
Max Memory Allocated: 0.03356790542602539  GigaBytes

{'VmPeak': 21897.9296875, 'VmSize': 21866.28515625, 'VmHWM': 4628.421875, 'VmRSS': 4628.421875}
torch.Size([1877, 1433])
torch.Size([1092, 256])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 12.2830810546875 GB
    Memory Allocated: 0.029814720153808594  GigaBytes
Max Memory Allocated: 0.03356790542602539  GigaBytes

{'VmPeak': 21897.9296875, 'VmSize': 21866.28515625, 'VmHWM': 4628.421875, 'VmRSS': 4628.421875}
{'VmPeak': 21897.9296875, 'VmSize': 21866.28515625, 'VmHWM': 4628.42578125, 'VmRSS': 4628.42578125}
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.01752793788909912 |0.0008821487426757812 |0.007709860801696777 |0.0002573728561401367 |0.005799770355224609 |0.00209808349609375 |
----------------------------------------------------------pseudo_mini_loss sum 0.8910768032073975
{'VmPeak': 21897.9296875, 'VmSize': 21866.28515625, 'VmHWM': 4628.42578125, 'VmRSS': 4628.42578125}
Total (block generation + training)time/epoch 10.75851821899414
Training time/epoch 0.07040214538574219
Training time without block to device /epoch 0.06863784790039062
Training time without total dataloading part /epoch 0.029632091522216797
load block tensor time/epoch 0.03505587577819824
block to device time/epoch 0.0017642974853515625
input features size transfer per epoch 2.682209014892578e-07
blocks size to device per epoch 1.7881393432617188e-07
 Run 0| Epoch 1 |
Number of nodes for computation during this epoch:  6514
Number of first layer input nodes during this epoch:  3690
